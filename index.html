<html>
  <head>

    <style>
    h1 {
      font-family: 'Open Sans', sans-serif;
      font-size: 25px;
      font-weight: 500;
      text-rendering: optimizeLegibility;
    }
    h2 {
      font-family: 'Open Sans', sans-serif;
      letter-spacing: 1px;
      letter-spacing: -0.015em;
      font-weight: 300;
      text-rendering: optimizeLegibility;
    }
    body {
        font-family: 'Open Sans', sans-serif;
        font: normal 12px/150% Arial, Helvetica, sans-serif;
        background: #fff;
    }
    table, td {
        border: 1px solid black;
        border-collapse: collapse;
        padding: 2px 2px;
        text-align: center;
    }
    th {
        padding: 3px 10px;
        font-family: 'Open Sans', sans-serif;
        font-weight: 100;
        background-color:#DADADA;
        color:#000000;
        font-size: 15px;
        border-left: 1px solid black;
        height: 30px;
    }
    table tr {
        color: #000000;
        border: 1px solid black;
        font-size: 12px;
        font-weight: normal;
        height: 40px;
    }
    audio {
      width: 120px;
      padding: 1px;
    }
    div {
      font-family: 'Open Sans', sans-serif;
      font-weight: 100;
      font-size: 15px;
      line-height: 24px;
    }
    </style>

    <meta charset="UTF-8">
    <title>Exploring Effective Speech Representation via ASR for High-Quality End-to-End Multispeaker TTS</title>
  </head>

  <body>
    <article>
      <header>
        <h1><font style="line-height:1.5;">"Exploring Effective Speech Representation via ASR for High-Quality End-to-End Multispeaker TTS"</font></h1>
      </header>
    </article>
    <!-- <br> -->
    <!-- <div style="font-size: 20px;"><b>Paper:</b> <a href="https://arxiv.org/">arXiv</a> </div> -->
    <br>
    <div style="font-size: 20px;"><b>Authors:</b> Dawei Liu, Longbiao Wang, Sheng Li, Haoyu Li, Chenchen Ding, Ju Zhang and Jianwu Dang</div>
    <br>
    <div style="font-size: 20px; width: 1200px;"><b>Abstract:</b> The quality of multispeaker text-to-speech (TTS) is composed of speech naturalness and speaker similarity. The current multispeaker TTS based on speaker embeddings extracted by speaker verification (SV) or speaker recognition (SR) models has made significant progress in speaker similarity of synthesized speech. SV/SR tasks build the speaker space based on the differences between speakers in the training set and thus extract speaker embeddings that can improve speaker similarity; however, they deteriorate the naturalness of synthetic speech since such embeddings lost speech dynamics to some extent. Unlike SV/SR-based systems, the ASR encoder outputs contain relatively complete speech information, such as speaker information, timbre, and prosody. Therefore, we propose an ASR-based synthesis framework to extract speech embeddings using an ASR encoder to improve multispeaker TTS quality, especially for speech naturalness. To enable the ASR system to learn the speaker characteristics better, we explicitly feed the speaker-id to the training label. The experimental results show that the speech embeddings extracted by the proposed method have good speaker characteristics and beneficial acoustic information for speech naturalness. The proposed method significantly improves the naturalness and similarity of multispeaker TTS.</div>

    <br>
    <br>

    <br>
    <br>
    <div><h2>Multi-Speaker TTS: the audios synthesized by multi-speaker TTS.</div>

    <br>
    <br>
    

    <br>
    <br>
    <br>

    <div style="font-size: 16px">Â© 2021 TJU. All rights reserved.</div>

  </body>
</html>
